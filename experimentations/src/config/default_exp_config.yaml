experiment:
    name: 'RotEquivariance'
    sub-experiment: 'default'
    sub-experiment-id: 0
    tags: {}


model:
    backbone: 'unet'
    steered: False
    nfeatures: 16
    nscale: 5
    depth: 2
    kernel: 5
    padding: 'auto'
    downsampling: 'maxpooling'
    upsampling: 'conv'
    batchnorm: True


training:
    seed: 1234
    dataset-file: 'av.h5'
    use-preprocess: True
    dataset-path: 'default'
    training-dataset: 'DRIVE'
    training-dataset-factor: 8
    max-epoch: 30
    val-every-n-epoch: 1
    half-precision: False
    optimize: 'val-acc'
    num-worker: 6
    early-stopping:
        monitor: 'train-loss'
        min_delta: 0.0005
        patience: 10
        mode: 'min'
    
hyper-parameters:
    lr: 1.e-2
    batch-size: 8
    accumulate-gradient-batch: 1
    drop-out: 0
    loss: 'binaryCE'  # 'focalLoss' / 'binaryCE' / 'dice'
    pos-weighted-loss: False
    smooth-label: 0
    optimizer:
        type: 'Adam' # also supported: AdamW and Adammax
        weight_decay: 0
        beta: 0.9       # coefficients used for computing running averages of gradient
        beta_sqr: 0.999 # and its square
        amsgrad: True

        lr-decay-factor: 0

data-augmentation:
    flip: True
    rotation: False
    elastic: False
    gamma: False # [-0.1, 0.1]
    brightness: False # [-0.1, 0.1]
    hue: False # [-20, 20]
    saturation: False # [-20, 20]